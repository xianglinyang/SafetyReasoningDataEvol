{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12d5a54",
   "metadata": {},
   "source": [
    "# Format the dataset into \n",
    "```python\n",
    "{\n",
    "    \"instruction\": ...,\n",
    "    \"cot\": ...,\n",
    "    \"answer\": ...,\n",
    "    \"mutations\":[{},{},...]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d193d506",
   "metadata": {},
   "source": [
    "# Reasoning to Defend (EMNLP'25)\n",
    "- 52k samples from Alpaca\n",
    "- 520 samples from AdvBench\n",
    "- DeepSeek-R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0773361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"chuhac/R2D-R1\")\n",
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f13b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. remove [] tage\n",
    "2. get the cot and answer\n",
    "'''\n",
    "def clean_output(output):\n",
    "    # remove tag\n",
    "    o = output.replace(\"[SAFE]\", \"\").replace(\"[UNSAFE]\", \"\").replace(\"[RETHINK]\", \"\")\n",
    "    return o\n",
    "\n",
    "def check_harmful(output):\n",
    "    if \"[UNSAFE]\" in output or \"I'm sorry\" in output:\n",
    "        return \"harmful\"\n",
    "    else:\n",
    "        return \"benign\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "benign_num = 0\n",
    "harmful_num = 0\n",
    "for item in ds['train']:\n",
    "    instruction = item['instruction']\n",
    "    input = item['input']\n",
    "    output = item['output']\n",
    "\n",
    "    typ = check_harmful(output)\n",
    "    if typ == \"benign\":\n",
    "        benign_num += 1\n",
    "    else:\n",
    "        harmful_num += 1\n",
    "    output = clean_output(output)\n",
    "\n",
    "    if len(instruction) > 2 and len(input) > 2:\n",
    "        question = instruction + \" \" + input\n",
    "\n",
    "        dataset.append({\n",
    "            \"instruction\": question.strip(),\n",
    "            \"output\": output,\n",
    "            \"type\": typ\n",
    "        })\n",
    "    elif len(instruction) > 2 and len(input) < 2:\n",
    "        question = instruction\n",
    "\n",
    "        dataset.append({\n",
    "            \"instruction\": question.strip(),\n",
    "            \"output\": output,\n",
    "            \"type\": typ\n",
    "        })\n",
    "    elif len(instruction) < 2 and len(input) > 2:\n",
    "        question = input\n",
    "\n",
    "        dataset.append({\n",
    "            \"instruction\": question.strip(),\n",
    "            \"output\": output,\n",
    "            \"type\": typ\n",
    "        })\n",
    "\n",
    "benign_num, harmful_num, dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6501d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "import json\n",
    "save_path = \"data/processed/R2D-R1.json\"\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2feb03",
   "metadata": {},
   "source": [
    "# SafeChain\n",
    "- 50,000 instructions from the WildJailbreak dataset using a uniform distribution.\n",
    "- R1-70B to generate 5 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1990c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"UWNSL/SafeChain\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb05b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output(output):\n",
    "    # split cot and answer\n",
    "    answer = output.split(\"</think>\")[-1].strip()\n",
    "    cot = output.split(\"</think>\")[0].strip()\n",
    "\n",
    "    return cot, answer\n",
    "\n",
    "dataset = []\n",
    "for item in ds['train']:\n",
    "    instruction = item['instruction']\n",
    "    label = item['label']\n",
    "    cot, answer = clean_output(item['response'])\n",
    "\n",
    "\n",
    "    dataset.append({\n",
    "        \"instruction\": instruction,\n",
    "        \"cot\": cot,\n",
    "        \"answer\": answer,\n",
    "        \"label\": label,\n",
    "    })\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "save_path = \"data/raw/SafeChain.json\"\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7d89bd",
   "metadata": {},
   "source": [
    "# Circuit breaker\n",
    "- self created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7663a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://raw.githubusercontent.com/GraySwanAI/circuit-breakers/refs/heads/main/data/circuit_breakers_train.json\n",
    "import requests\n",
    "url = \"https://raw.githubusercontent.com/GraySwanAI/circuit-breakers/refs/heads/main/data/circuit_breakers_train.json\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb88c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should filter again, not clean enough\n",
    "dataset = []\n",
    "\n",
    "for item in data:\n",
    "    answer = item['llama3_output']\n",
    "\n",
    "    if \"cannot\" in answer:\n",
    "\n",
    "        new_item = item.copy()\n",
    "        new_item['instruction'] = item['prompt']\n",
    "        new_item['answer'] = answer\n",
    "        new_item['label'] = item['category']\n",
    "        dataset.append(new_item)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "len(dataset), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b385ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "import os\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "import json\n",
    "save_path = \"data/raw/circuit_breakers_train.json\"\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/GraySwanAI/circuit-breakers/refs/heads/main/data/circuit_breakers_val.json\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfafe4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should filter again, not clean enough\n",
    "dataset = []\n",
    "\n",
    "for item in data:\n",
    "    answer = item['llama3_output']\n",
    "    new_item = item.copy()\n",
    "    new_item['instruction'] = item['prompt']\n",
    "    new_item['answer'] = answer\n",
    "    dataset.append(new_item)\n",
    "\n",
    "len(dataset), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "import json\n",
    "save_path = \"data/raw/circuit_breakers_val.json\"\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b04f5de",
   "metadata": {},
   "source": [
    "# STAIR\n",
    "- Ultrafeedback\n",
    "- SafeRLHF\n",
    "- JailBreakV\n",
    "\n",
    "to construct both a SFT dataset of 20k samples for CoT format alignment and a seed dataset with prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4507494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"thu-ml/STAIR-SFT\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb14128",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([item['source'] for item in ds['train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72dfb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "harmful_num = 0\n",
    "benign_num = 0\n",
    "for item in ds['train']:\n",
    "    instruction = item['prompt']\n",
    "    answer = item['answer']\n",
    "    if \"PKU-SafeRLHF\" in item['source']:\n",
    "        harmful_num += 1\n",
    "    else:\n",
    "        benign_num += 1\n",
    "\n",
    "    dataset.append({\n",
    "        \"instruction\": instruction,\n",
    "        \"answer\": answer,\n",
    "        \"type\": \"harmful\" if \"PKU-SafeRLHF\" in item['source'] else \"benign\",\n",
    "        \"source\": item['source']\n",
    "    })\n",
    "\n",
    "harmful_num, benign_num, len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3edb752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "save_path = \"data/processed/STAIR-SFT.json\"\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52637439",
   "metadata": {},
   "source": [
    "# SRG\n",
    "- PKUSafeRLHF (Ji et al., 2024) and helpful instructions from\n",
    "- Ultrafeedback (Cui et al., 2023), \n",
    "- with corresponding responses re-generated by GPT-4o with guidelines (tags)\n",
    "\n",
    "We experiment with two dataset scales: \n",
    "(1) small-scale (0.8K illegal, 2.5K helpful)\n",
    "(2) large-scale (5K illegal, 30K helpful)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not released!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ad4a1",
   "metadata": {},
   "source": [
    "# AlphaAlign\n",
    "- SCoT data\n",
    "- Dolly\n",
    "- XSTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44ab85",
   "metadata": {},
   "source": [
    "# Dolly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29713961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# dataset keys: category, prompt, llama3_output\n",
    "ds = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcca2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67854a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for item in ds:\n",
    "    context = item['context']\n",
    "    instruction = item['instruction']\n",
    "\n",
    "    instruction = context + \" \" + instruction\n",
    "    category = item['category']\n",
    "    answer = item['response']\n",
    "    dataset.append({\n",
    "        \"category\": category,\n",
    "        \"answer\": answer,\n",
    "        \"instruction\": instruction,\n",
    "    })\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c44aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "import json\n",
    "path = \"data/raw/dolly.json\"\n",
    "with open(path, \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
